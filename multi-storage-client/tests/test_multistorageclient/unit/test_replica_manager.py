# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
import time
import uuid
from typing import Any, Dict, Tuple, Union
from unittest.mock import patch

import pytest

from multistorageclient import StorageClient, StorageClientConfig
from multistorageclient.types import ExecutionMode
from test_multistorageclient.e2e.common import wait
from test_multistorageclient.unit.utils import tempdatastore

# Type alias for configuration dictionary to avoid complex nested types
ConfigDict = Dict[str, Any]


def create_basic_replica_config(
    origin_store: tempdatastore.TemporaryDataStore,
    replica_store: tempdatastore.TemporaryDataStore,
    origin_profile: str = "origin",
    replica_profile: str = "replica",
    origin_with_replica_profile: str = "origin_with_replica",
) -> ConfigDict:
    """Create a basic configuration with origin and single replica."""
    return {
        "profiles": {
            origin_profile: origin_store.profile_config_dict(),
            replica_profile: replica_store.profile_config_dict(),
            origin_with_replica_profile: origin_store.profile_config_dict()
            | {"replicas": [{"replica_profile": replica_profile, "read_priority": 1}]},
        }
    }


def create_multiple_replica_config(
    origin_store: tempdatastore.TemporaryDataStore,
    replica1_store: tempdatastore.TemporaryDataStore,
    replica2_store: tempdatastore.TemporaryDataStore,
    origin_profile: str = "origin",
    replica1_profile: str = "replica1",
    replica2_profile: str = "replica2",
    origin_with_replicas_profile: str = "origin_with_replicas",
) -> ConfigDict:
    """Create a configuration with origin and multiple replicas."""
    return {
        "profiles": {
            origin_profile: origin_store.profile_config_dict(),
            replica1_profile: replica1_store.profile_config_dict(),
            replica2_profile: replica2_store.profile_config_dict(),
            origin_with_replicas_profile: origin_store.profile_config_dict()
            | {
                "replicas": [
                    {"replica_profile": replica1_profile, "read_priority": 1},
                    {"replica_profile": replica2_profile, "read_priority": 2},
                ]
            },
        }
    }


def create_cache_config(base_config: ConfigDict) -> ConfigDict:
    """Add cache configuration to an existing config."""
    config = base_config.copy()
    config["cache"] = {
        "size": "10M",
        "use_etag": True,
        "location": tempfile.mkdtemp(),
        "eviction_policy": {
            "policy": "random",
        },
    }
    return config


def create_test_clients(
    config: ConfigDict, origin_profile: str = "origin", origin_with_replica_profile: str = "origin_with_replica"
) -> Tuple[StorageClient, StorageClient]:
    """Create origin and replica-aware clients from config."""
    origin_client = StorageClient(config=StorageClientConfig.from_dict(config, profile=origin_profile))
    origin_with_replica_client = StorageClient(
        config=StorageClientConfig.from_dict(config, profile=origin_with_replica_profile)
    )
    return origin_client, origin_with_replica_client


def write_and_verify_origin_file(
    origin_client: StorageClient, test_file_path: str, test_content: Union[str, bytes]
) -> None:
    """Write content to origin and verify it exists."""
    origin_client.write(test_file_path, test_content)
    assert origin_client.is_file(test_file_path), f"File {test_file_path} should exist in origin storage"


def verify_replicas_have_file(
    origin_with_replica_client: StorageClient, test_file_path: str, test_content: Union[str, bytes]
) -> None:
    """Verify that all replicas have the file with correct content."""
    for replica in origin_with_replica_client.replicas:
        assert replica.is_file(test_file_path), f"File {test_file_path} should exist in replica {replica.profile}"
        replica_content = replica.read(test_file_path)
        assert replica_content == test_content, (
            f"Replica {replica.profile} should have the same content as origin: expected {test_content}, got {replica_content}"
        )


def wait_for_replicas_to_have_file(origin_with_replica_client: StorageClient, test_file_path: str) -> None:
    """Wait for all replicas to have the specified file."""
    wait(
        waitable=lambda: all(replica.is_file(test_file_path) for replica in origin_with_replica_client.replicas),
        should_wait=lambda all_exist: not all_exist,
        max_attempts=3,
        attempt_interval_seconds=1,
    )


def test_replica_read_from_replica_after_sync() -> None:
    """Test that data written to origin store can be read from replica after sync_replicas."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica_store,
    ):
        # Create configuration and clients
        config = create_basic_replica_config(origin_store, replica_store)
        origin_client, origin_with_replica_client = create_test_clients(config)

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.bin"
        test_content = b"This is test content for replica testing"

        # Step 1: Write data to origin store
        write_and_verify_origin_file(origin_client, test_file_path, test_content)

        # Step 2: Sync replicas
        origin_with_replica_client.sync_replicas("", execution_mode=ExecutionMode.LOCAL)

        # Step 3: Verify replicas are configured
        assert hasattr(origin_with_replica_client, "replicas"), "Client should have replicas attribute"
        assert origin_with_replica_client.replicas is not None, "Replicas should not be None"
        assert len(origin_with_replica_client.replicas) > 0, "At least one replica should be configured"

        # Step 4: Verify file exists in replica
        verify_replicas_have_file(origin_with_replica_client, test_file_path, test_content)

        # Step 5: Read from replica (this should trigger replica-aware reading)
        content_from_replica = origin_with_replica_client.read(test_file_path)

        # Step 6: Verify content from replica matches original content
        assert content_from_replica == test_content, (
            f"Content from replica mismatch: expected {test_content}, got {content_from_replica}"
        )


def test_replica_read_with_multiple_replicas() -> None:
    """Test replica reading with multiple replicas configured."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica1_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica2_store,
    ):
        # Create configuration and clients
        config = create_multiple_replica_config(origin_store, replica1_store, replica2_store)
        origin_client, origin_with_replicas_client = create_test_clients(
            config, origin_with_replica_profile="origin_with_replicas"
        )

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.bin"
        test_content = b"This is test content for multiple replica testing"

        # Step 1: Write data to origin store
        write_and_verify_origin_file(origin_client, test_file_path, test_content)

        # Step 2: Sync replicas
        origin_with_replicas_client.sync_replicas("", execution_mode=ExecutionMode.LOCAL)

        # Step 3: Verify multiple replicas are configured
        assert len(origin_with_replicas_client.replicas) == 2, "Should have exactly 2 replicas configured"

        # Step 4: Verify file exists in all replicas with the same content
        verify_replicas_have_file(origin_with_replicas_client, test_file_path, test_content)

        # Step 5: Alter the file on the lower-priority replica (replica2)
        # This will test that read_priority is respected when replicas have different content
        altered_content = b"This is altered content in replica2"
        replica2_client = StorageClient(config=StorageClientConfig.from_dict(config, profile="replica2"))
        replica2_client.write(test_file_path, altered_content)

        # Verify replica2 now has different content
        assert replica2_client.read(test_file_path) == altered_content, "Replica2 should have altered content"

        # Step 6: Read from replicas (should use replica with highest priority first)
        # The replica manager should respect read_priority and read from replica1 (priority 1) first
        content_from_replica = origin_with_replicas_client.read(test_file_path)

        # Step 7: Verify content from replica matches the original content from replica1 (highest priority)
        # Since replica1 has the original content and replica2 has altered content,
        # and replica1 has higher priority (1 vs 2), we should get the original content
        assert content_from_replica == test_content, (
            f"Content from replica should match original content from highest-priority replica: expected {test_content}, got {content_from_replica}"
        )


@pytest.mark.skip(reason="Test failing due to multiprocessing timeout issues in CI")
def test_replica_read_with_cache() -> None:
    """Test replica reading with cache enabled."""
    with (
        tempdatastore.TemporaryAWSS3Bucket() as origin_store,
        tempdatastore.TemporaryAWSS3Bucket() as replica_store,
    ):
        # Create configuration and clients
        config = create_basic_replica_config(origin_store, replica_store)
        config = create_cache_config(config)
        origin_client, origin_with_replica_client = create_test_clients(config)

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.bin"
        test_content = b"This is test content for replica testing with cache"

        # Step 1: Write data to origin store
        write_and_verify_origin_file(origin_client, test_file_path, test_content)

        # Step 2: Sync replicas
        origin_with_replica_client.sync_replicas("", execution_mode=ExecutionMode.LOCAL)

        # Step 3: Verify cache is configured
        assert origin_with_replica_client._cache_manager is not None, "Cache manager should be configured"

        # Step 4: Read from replica (should use cache if available, then replica)
        content_from_replica = origin_with_replica_client.read(test_file_path)

        # Step 5: Verify content from replica matches original content
        assert content_from_replica == test_content, (
            f"Content from replica mismatch: expected {test_content}, got {content_from_replica}"
        )


@pytest.mark.parametrize(
    "test_content,file_extension,encode_content",
    [
        ("This is test content for string content testing", ".txt", True),
        (b"This is test content for bytes content testing", ".bin", False),
    ],
)
def test_async_replica_upload_with_different_content_types(
    test_content: Union[str, bytes], file_extension: str, encode_content: bool
) -> None:
    """Test async replica upload with different content types."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica_store,
    ):
        # Create configuration and clients
        config = create_basic_replica_config(origin_store, replica_store)
        origin_client, origin_with_replica_client = create_test_clients(config)

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile{file_extension}"

        # Step 1: Write data to origin store
        if encode_content:
            if isinstance(test_content, str):
                origin_client.write(test_file_path, test_content.encode("utf-8"))
            else:
                origin_client.write(test_file_path, test_content)
        else:
            origin_client.write(test_file_path, test_content)

        # Step 2: Use client.read to read file (should trigger async upload to replicas)
        content_from_replica = origin_with_replica_client.read(test_file_path)

        # Step 3: Verify content was read correctly
        if encode_content:
            # For string content, decode bytes to string for comparison
            assert content_from_replica.decode("utf-8") == test_content, (
                f"Content from replica mismatch: expected {test_content}, got {content_from_replica.decode('utf-8')}"
            )
        else:
            # For bytes content, compare directly
            assert content_from_replica == test_content, (
                f"Content from replica mismatch: expected {test_content}, got {content_from_replica}"
            )

        # Step 4: Wait for file to appear in replica and verify content (background upload might still be running)
        wait_for_replicas_to_have_file(origin_with_replica_client, test_file_path)

        # Verify all replicas have the file and correct content
        for replica in origin_with_replica_client.replicas:
            assert replica.is_file(test_file_path), f"File {test_file_path} should exist in replica {replica.profile}"
            replica_content = replica.read(test_file_path)

            if encode_content:
                # For string content, decode bytes to string for comparison
                replica_content_str = replica_content.decode("utf-8")
                assert replica_content_str == test_content, (
                    f"Replica {replica.profile} content mismatch: expected {test_content}, got {replica_content_str}"
                )
            else:
                # For bytes content, compare directly
                assert replica_content == test_content, (
                    f"Replica {replica.profile} content mismatch: expected {test_content}, got {replica_content}"
                )


def test_async_replica_upload_thread_pool_configuration() -> None:
    """Test that the thread pool is configured correctly with environment variable."""

    # Clear any existing environment variable
    if "MSC_REPLICA_UPLOAD_THREADS" in os.environ:
        del os.environ["MSC_REPLICA_UPLOAD_THREADS"]

    # Create a new ReplicaManager instance to test default configuration
    # The thread pool is class-level, so we need to check its configuration
    # We can't easily test this without modifying the class, but we can verify
    # that the environment variable is read correctly

    # Test with custom environment variable
    os.environ["MSC_REPLICA_UPLOAD_THREADS"] = "4"

    # Create a new ReplicaManager to test custom configuration
    # Note: This is a bit of a hack since the thread pool is class-level
    # In a real scenario, you might want to add a method to check the thread pool configuration

    # For now, we'll just verify that the environment variable is set correctly
    assert os.environ["MSC_REPLICA_UPLOAD_THREADS"] == "4"

    # Clean up
    del os.environ["MSC_REPLICA_UPLOAD_THREADS"]


def test_async_replica_upload_multiple_replicas() -> None:
    """Test async replica upload with multiple replicas."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica1_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica2_store,
    ):
        # Create configuration and clients
        config = create_multiple_replica_config(origin_store, replica1_store, replica2_store)
        origin_client, origin_with_replicas_client = create_test_clients(
            config, origin_with_replica_profile="origin_with_replicas"
        )

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.txt"
        test_content = "This is test content for multiple replica async upload testing"

        # Step 1: Write data to origin store
        origin_client.write(test_file_path, test_content.encode("utf-8"))

        # Step 2: Use client.read to read file (should trigger async upload to replicas)
        content_from_replica = origin_with_replicas_client.read(test_file_path)

        # Step 3: Verify content was read correctly as string
        assert content_from_replica.decode("utf-8") == test_content, (
            f"Content from replica mismatch: expected {test_content}, got {content_from_replica.decode('utf-8')}"
        )

        # Step 4: Wait for files to appear in all replicas and verify content (background upload might still be running)
        wait_for_replicas_to_have_file(origin_with_replicas_client, test_file_path)

        # Verify all replicas have the file and correct content
        for replica in origin_with_replicas_client.replicas:
            assert replica.is_file(test_file_path), f"File {test_file_path} should exist in replica {replica.profile}"
            replica_content = replica.read(test_file_path)
            assert replica_content.decode("utf-8") == test_content, (
                f"Replica {replica.profile} content mismatch: expected {test_content}, got {replica_content.decode('utf-8')}"
            )


def test_async_replica_upload_exception_handling() -> None:
    """Test that exceptions in background replica uploads are properly handled and logged."""

    # Create a mock storage client and replica manager
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica_store,
    ):
        config = create_basic_replica_config(origin_store, replica_store)
        _, origin_with_replica_client = create_test_clients(config)

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.txt"
        test_content = "This is test content for exception handling"

        # Write data to origin store
        write_and_verify_origin_file(origin_with_replica_client, test_file_path, test_content.encode("utf-8"))

        # Explicitly delete the file from replica to ensure background upload is triggered
        if origin_with_replica_client.replicas[0].is_file(test_file_path):
            origin_with_replica_client.replicas[0].delete(test_file_path)

        # Mock the replica's upload_file method to fail - this will cause the background upload to fail
        def mock_upload_file_with_exception(*args: Any, **kwargs: Any) -> None:
            raise Exception("Replica upload failed for testing")

        # Patch the upload_file method at the class level to ensure it works in background threads
        replica_client_class = type(origin_with_replica_client.replicas[0])

        with patch.object(replica_client_class, "upload_file", side_effect=mock_upload_file_with_exception):
            # Read from replica-aware client - this should:
            # 1. Read from primary (succeed)
            # 2. Submit background upload to thread pool
            # 3. Background thread calls replica.upload_file() â†’ EXCEPTION
            # 4. Exception is logged directly in the background thread
            content = origin_with_replica_client.read(test_file_path)

            # Verify read succeeded (from primary)
            assert content.decode("utf-8") == test_content, "Read should succeed from primary"

            # Wait for background thread to complete
            time.sleep(2.0)

            # Verify that the background upload was attempted and exception was handled
            # The exception should be logged directly in the background thread
            # We can verify this by checking that the file still doesn't exist in the replica
            # (since our mock upload_file always raises an exception)
            assert not origin_with_replica_client.replicas[0].is_file(test_file_path), (
                "File should not exist in replica since upload was mocked to fail"
            )


def test_duplicate_upload_prevention() -> None:
    """Test that duplicate upload attempts for the same file are prevented."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica_store,
    ):
        # Create configuration with replicas
        config = create_basic_replica_config(origin_store, replica_store)
        origin_client, origin_with_replica_client = create_test_clients(config)

        # Create test file in origin
        test_file_path = f"test_file_{uuid.uuid4()}.txt"
        test_content = "Test content for duplicate upload prevention"
        write_and_verify_origin_file(origin_client, test_file_path, test_content.encode("utf-8"))

        # Verify replica doesn't have the file initially
        replica_client = origin_with_replica_client.replicas[0]
        assert not replica_client.is_file(test_file_path), f"Replica should not have file {test_file_path} initially"

        # Track upload attempts by mocking the upload_file method
        upload_count = 0
        original_upload_file = replica_client.upload_file

        def mock_upload_file(*args, **kwargs):
            nonlocal upload_count
            upload_count += 1
            return original_upload_file(*args, **kwargs)

        # Apply the mock
        with patch.object(replica_client, "upload_file", side_effect=mock_upload_file):
            # Read the file multiple times - this should trigger upload only once
            for i in range(3):
                content = origin_with_replica_client.read(test_file_path)
                assert content.decode("utf-8") == test_content, f"Read {i + 1}: Content should match"
                # Add delay to prevent race condition in duplicate upload prevention
                time.sleep(0.3)

            # Wait for replica to have the file
            wait_for_replicas_to_have_file(origin_with_replica_client, test_file_path)

            # Verify replica has the file
            assert replica_client.is_file(test_file_path), f"Replica should have file {test_file_path} after upload"

            # Verify content
            content = replica_client.read(test_file_path)
            assert content.decode("utf-8") == test_content, "Replica should have correct content"

            # Verify that upload was triggered only once
            assert upload_count == 1, f"Upload should be triggered only once, but was triggered {upload_count} times"


def test_storage_client_delete_with_replicas() -> None:
    """Test StorageClient.delete() method with replicas configured."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica_store,
    ):
        # Create configuration and clients
        config = create_basic_replica_config(origin_store, replica_store)
        origin_client, origin_with_replica_client = create_test_clients(config)

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.txt"
        test_content = b"This is test content for storage client delete testing"

        # Step 1: Write data to origin store
        write_and_verify_origin_file(origin_client, test_file_path, test_content)

        # Step 2: Sync replicas to ensure file exists in replica
        origin_with_replica_client.sync_replicas("", execution_mode=ExecutionMode.LOCAL)

        # Step 3: Verify file exists in replica
        replica_client = StorageClient(config=StorageClientConfig.from_dict(config, profile="replica"))
        assert replica_client.is_file(test_file_path), f"File {test_file_path} should exist in replica after sync"

        # Step 4: Delete file using origin_with_replica_client (which has replica manager)
        origin_with_replica_client.delete(test_file_path)

        # Step 5: Verify file is deleted from both origin and replica
        assert not origin_client.is_file(test_file_path), f"File {test_file_path} should be deleted from origin"
        assert not replica_client.is_file(test_file_path), f"File {test_file_path} should be deleted from replica"


def test_storage_client_delete_with_multiple_replicas() -> None:
    """Test StorageClient.delete() method with multiple replicas configured."""
    with (
        tempdatastore.TemporaryPOSIXDirectory() as origin_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica1_store,
        tempdatastore.TemporaryPOSIXDirectory() as replica2_store,
    ):
        # Create configuration and clients
        config = create_multiple_replica_config(origin_store, replica1_store, replica2_store)
        origin_client, origin_with_replicas_client = create_test_clients(
            config, origin_with_replica_profile="origin_with_replicas"
        )

        # Test data
        test_file_path = f"test-data-{uuid.uuid4()}/testfile.txt"
        test_content = b"This is test content for multiple replica delete testing"

        # Step 1: Write data to origin store
        write_and_verify_origin_file(origin_client, test_file_path, test_content)

        # Step 2: Sync replicas to ensure file exists in all replicas
        origin_with_replicas_client.sync_replicas("", execution_mode=ExecutionMode.LOCAL)

        # Step 3: Verify file exists in all replicas
        replica1_client = StorageClient(config=StorageClientConfig.from_dict(config, profile="replica1"))
        replica2_client = StorageClient(config=StorageClientConfig.from_dict(config, profile="replica2"))

        assert replica1_client.is_file(test_file_path), f"File {test_file_path} should exist in replica1 after sync"
        assert replica2_client.is_file(test_file_path), f"File {test_file_path} should exist in replica2 after sync"

        # Step 4: Delete file using origin_with_replicas_client (which has replica manager)
        origin_with_replicas_client.delete(test_file_path)

        # Step 5: Verify file is deleted from origin and all replicas
        assert not origin_client.is_file(test_file_path), f"File {test_file_path} should be deleted from origin"
        assert not replica1_client.is_file(test_file_path), f"File {test_file_path} should be deleted from replica1"
        assert not replica2_client.is_file(test_file_path), f"File {test_file_path} should be deleted from replica2"
